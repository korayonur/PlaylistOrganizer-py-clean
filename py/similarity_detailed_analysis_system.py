#!/usr/bin/env python3
"""
DetaylÄ± Benzerlik Analiz Sistemi
===============================

Bu sistem ÅŸu analizleri yapar:
1. Log dosyasÄ±ndaki eÅŸleÅŸmeleri detaylÄ± analiz eder
2. VeritabanÄ±ndaki dosya yapÄ±larÄ±nÄ± analiz eder
3. Benzerlik algoritmasÄ±nÄ±n performansÄ±nÄ± deÄŸerlendirir
4. MantÄ±ksÄ±z eÅŸleÅŸmeleri tespit eder
5. Ã–neriler sunar
"""

import json
import re
import os
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Tuple, Any
from collections import Counter, defaultdict
import statistics

class SimilarityDetailedAnalysisSystem:
    def __init__(self, log_file_path: str, db_file_path: str):
        self.log_file_path = log_file_path
        self.db_file_path = db_file_path
        self.log_data = None
        self.db_data = None
        self.analysis_results = {}
        
    def load_data(self):
        """Verileri yÃ¼kle"""
        print("ğŸ“ Veriler yÃ¼kleniyor...")
        
        # Log dosyasÄ±nÄ± yÃ¼kle
        try:
            with open(self.log_file_path, 'r', encoding='utf-8') as f:
                self.log_data = json.load(f)
            print(f"âœ… Log dosyasÄ± yÃ¼klendi: {len(self.log_data['response_data']['results'])} sonuÃ§")
        except Exception as e:
            print(f"âŒ Log dosyasÄ± yÃ¼klenemedi: {e}")
            return False
            
        # VeritabanÄ±nÄ± yÃ¼kle
        try:
            with open(self.db_file_path, 'r', encoding='utf-8') as f:
                self.db_data = json.load(f)
            print(f"âœ… VeritabanÄ± yÃ¼klendi: {len(self.db_data.get('musicFiles', []))} dosya")
        except Exception as e:
            print(f"âŒ VeritabanÄ± yÃ¼klenemedi: {e}")
            return False
            
        return True
    
    def analyze_similarity_algorithm_focus(self):
        """Benzerlik algoritmasÄ±na odaklÄ± analiz"""
        print("\nğŸ¯ BENZERLÄ°K ALGORÄ°TMASI ODAKLI ANALÄ°Z")
        print("=" * 60)
        
        # Sadece benzerlik algoritmasÄ± ile eÅŸleÅŸen dosyalarÄ± analiz et
        similarity_matches = []
        for result in self.log_data['response_data']['results']:
            if (result.get('found') and 
                result.get('matchType') == 'benzerDosya' and 
                'similarity' in result):
                similarity_matches.append(result)
        
        print(f"ğŸ“Š Benzerlik algoritmasÄ± ile eÅŸleÅŸen dosya sayÄ±sÄ±: {len(similarity_matches)}")
        
        # Benzerlik skorlarÄ±nÄ± analiz et
        similarities = [match['similarity'] for match in similarity_matches]
        if similarities:
            print(f"ğŸ“ˆ Benzerlik skorlarÄ±:")
            print(f"   Ortalama: {statistics.mean(similarities):.3f}")
            print(f"   Medyan: {statistics.median(similarities):.3f}")
            print(f"   En dÃ¼ÅŸÃ¼k: {min(similarities):.3f}")
            print(f"   En yÃ¼ksek: {max(similarities):.3f}")
        
        self.analysis_results['similarity_focus'] = {
            'total_matches': len(similarity_matches),
            'similarities': similarities,
            'matches': similarity_matches
        }
        
        return similarity_matches
    
    def _classify_file_name(self, file_name: str) -> str:
        """Dosya adÄ±nÄ± kategorize et"""
        file_lower = file_name.lower()
        
        # SanatÃ§Ä± - ÅarkÄ± formatÄ± (tire ile ayrÄ±lmÄ±ÅŸ)
        if ' - ' in file_name and len(file_name.split(' - ')) == 2:
            return 'sanatci_sarki'
        
        # Mix/Compilation
        if any(word in file_lower for word in ['mix', 'compilation', 'playlist', 'album', 'collection']):
            return 'mix_compilation'
        
        # DJ/Remix
        if any(word in file_lower for word in ['dj', 'remix', 'feat', 'ft', 'featuring']):
            return 'dj_remix'
        
        # EnstrÃ¼mantal
        if any(word in file_lower for word in ['instrumental', 'enstrÃ¼mantal', 'piyano', 'gitar', 'saz']):
            return 'instrumental'
        
        # Playlist/Album
        if any(word in file_lower for word in ['top', 'best', 'hits', 'classics', 'greatest']):
            return 'playlist_album'
        
        # Sadece ÅŸarkÄ± adÄ± (kÄ±sa)
        if len(file_name.split()) <= 3:
            return 'sadece_sarki'
        
        return 'other'
    
    def analyze_problematic_matches(self):
        """Problemli eÅŸleÅŸmeleri detaylÄ± analiz et"""
        print("\nâš ï¸  PROBLEMLÄ° EÅLEÅMELER DETAYLI ANALÄ°ZÄ°")
        print("=" * 60)
        
        # Genel kelimeleri tanÄ±mla
        common_words = {'remix', 'mix', 'dj', 'feat', 'ft', 'music', 'song', 'mp3', 'm4a', 'flac', 'wmv', 'the', 'a', 'an', 'and', 'or', 'of', 'in', 'on', 'at', 'to', 'for', 'with', 'by'}
        
        problematic_matches = []
        low_quality_matches = []
        general_word_matches = []
        
        for result in self.log_data['response_data']['results']:
            if (result.get('found') and 
                result.get('matchType') == 'benzerDosya' and 
                'similarity' in result):
                
                sim = result['similarity']
                original = result['originalPath'].split('/')[-1]
                found = result['foundPath'].split('/')[-1]
                
                # Ortak kelimeleri hesapla
                orig_words = set(re.findall(r'[a-zA-ZÃ§ÄŸÄ±Ã¶ÅŸÃ¼Ã‡ÄIÄ°Ã–ÅÃœ]+', original.lower()))
                found_words = set(re.findall(r'[a-zA-ZÃ§ÄŸÄ±Ã¶ÅŸÃ¼Ã‡ÄIÄ°Ã–ÅÃœ]+', found.lower()))
                common_words_set = orig_words & found_words
                common_words_list = list(common_words_set)
                
                # Problemli eÅŸleÅŸme kategorileri
                match_info = {
                    'similarity': sim,
                    'original': original,
                    'found': found,
                    'common_words': common_words_list,
                    'common_count': len(common_words_list),
                    'non_general_words': list(common_words_set - common_words),
                    'non_general_count': len(common_words_set - common_words)
                }
                
                # DÃ¼ÅŸÃ¼k benzerlik (< 0.7)
                if sim < 0.7:
                    problematic_matches.append(match_info)
                
                # DÃ¼ÅŸÃ¼k kalite (az ortak kelime)
                if len(common_words_list) < 3 and sim < 0.9:
                    low_quality_matches.append(match_info)
                
                # Genel kelime baÄŸÄ±mlÄ± eÅŸleÅŸme
                if len(common_words_set - common_words) < 2 and sim < 0.9:
                    general_word_matches.append(match_info)
        
        # SonuÃ§larÄ± yazdÄ±r
        print(f"ğŸ“Š Problemli EÅŸleÅŸme Kategorileri:")
        print(f"   DÃ¼ÅŸÃ¼k benzerlik (< 0.7): {len(problematic_matches)}")
        print(f"   DÃ¼ÅŸÃ¼k kalite (az ortak kelime): {len(low_quality_matches)}")
        print(f"   Genel kelime baÄŸÄ±mlÄ±: {len(general_word_matches)}")
        
        # En problemli eÅŸleÅŸmeleri gÃ¶ster
        print(f"\nğŸ” EN PROBLEMLÄ° EÅLEÅMELER:")
        all_problematic = sorted(problematic_matches + low_quality_matches + general_word_matches, 
                               key=lambda x: x['similarity'])
        
        for i, match in enumerate(all_problematic[:15]):  # En problemli 15 Ã¶rnek
            print(f"\n{i+1}. Benzerlik: {match['similarity']:.3f}")
            print(f"   Orijinal: {match['original']}")
            print(f"   Bulunan:  {match['found']}")
            print(f"   Ortak kelimeler: {match['common_words']} ({match['common_count']} adet)")
            print(f"   Genel olmayan kelimeler: {match['non_general_words']} ({match['non_general_count']} adet)")
        
        self.analysis_results['problematic_analysis'] = {
            'problematic_matches': problematic_matches,
            'low_quality_matches': low_quality_matches,
            'general_word_matches': general_word_matches,
            'common_words': common_words
        }
        
        return problematic_matches
    
    def analyze_database_structure(self):
        """VeritabanÄ± yapÄ±sÄ±nÄ± analiz et"""
        print("\nğŸ—„ï¸  VERÄ°TABANI YAPISI ANALÄ°ZÄ°")
        print("=" * 60)
        
        if not self.db_data or 'musicFiles' not in self.db_data:
            print("âŒ VeritabanÄ± verisi bulunamadÄ±")
            return {}
        
        music_files = self.db_data['musicFiles']
        print(f"ğŸ“ Toplam dosya sayÄ±sÄ±: {len(music_files)}")
        
        # Dosya uzantÄ±larÄ±
        extensions = Counter()
        for file_info in music_files:
            if 'path' in file_info:
                ext = Path(file_info['path']).suffix.lower()
                extensions[ext] += 1
        
        print(f"\nğŸ“Š Dosya UzantÄ±larÄ±:")
        for ext, count in extensions.most_common():
            percentage = (count / len(music_files)) * 100
            print(f"   {ext}: {count} dosya (%{percentage:.1f})")
        
        # Kelime analizi
        word_analysis = self._analyze_words_in_database(music_files)
        
        # KlasÃ¶r analizi
        folder_analysis = self._analyze_folders_in_database(music_files)
        
        self.analysis_results['database_structure'] = {
            'total_files': len(music_files),
            'extensions': dict(extensions),
            'word_analysis': word_analysis,
            'folder_analysis': folder_analysis
        }
        
        return self.analysis_results['database_structure']
    
    def _analyze_words_in_database(self, music_files: List[Dict]) -> Dict:
        """VeritabanÄ±ndaki kelimeleri analiz et"""
        print(f"\nğŸ”¤ Kelime Analizi:")
        
        all_words = []
        file_words = []
        folder_words = []
        
        for file_info in music_files:
            if 'allWords' in file_info:
                all_words.extend(file_info['allWords'])
            if 'fileWords' in file_info:
                file_words.extend(file_info['fileWords'])
            if 'folderWords' in file_info:
                folder_words.extend(file_info['folderWords'])
        
        # En sÄ±k kullanÄ±lan kelimeler
        word_counts = Counter(all_words)
        file_word_counts = Counter(file_words)
        folder_word_counts = Counter(folder_words)
        
        print(f"   Toplam kelime: {len(all_words)}")
        print(f"   Benzersiz kelime: {len(word_counts)}")
        
        print(f"\n   En sÄ±k kullanÄ±lan kelimeler (genel):")
        for word, count in word_counts.most_common(10):
            print(f"     {word}: {count}")
        
        print(f"\n   En sÄ±k kullanÄ±lan kelimeler (dosya adÄ±):")
        for word, count in file_word_counts.most_common(10):
            print(f"     {word}: {count}")
        
        return {
            'total_words': len(all_words),
            'unique_words': len(word_counts),
            'most_common_words': dict(word_counts.most_common(20)),
            'most_common_file_words': dict(file_word_counts.most_common(20)),
            'most_common_folder_words': dict(folder_word_counts.most_common(20))
        }
    
    def _analyze_folders_in_database(self, music_files: List[Dict]) -> Dict:
        """KlasÃ¶r yapÄ±sÄ±nÄ± analiz et"""
        print(f"\nğŸ“ KlasÃ¶r Analizi:")
        
        folder_counts = Counter()
        folder_depth_counts = Counter()
        
        for file_info in music_files:
            if 'path' in file_info:
                path_parts = Path(file_info['path']).parts
                folder_depth = len(path_parts) - 1  # Dosya adÄ± hariÃ§
                folder_depth_counts[folder_depth] += 1
                
                # Ana klasÃ¶rleri say
                if len(path_parts) > 1:
                    main_folder = path_parts[-2]  # Son klasÃ¶r
                    folder_counts[main_folder] += 1
        
        print(f"   KlasÃ¶r derinliÄŸi daÄŸÄ±lÄ±mÄ±:")
        for depth, count in sorted(folder_depth_counts.items()):
            print(f"     {depth} seviye: {count} dosya")
        
        print(f"\n   En sÄ±k kullanÄ±lan klasÃ¶rler:")
        for folder, count in folder_counts.most_common(10):
            print(f"     {folder}: {count} dosya")
        
        return {
            'folder_counts': dict(folder_counts),
            'depth_distribution': dict(folder_depth_counts)
        }
    
    def analyze_algorithm_performance(self):
        """Algoritma performansÄ±nÄ± analiz et"""
        print("\nâš¡ ALGORÄ°TMA PERFORMANS ANALÄ°ZÄ°")
        print("=" * 60)
        
        if 'matchDetails' not in self.log_data['response_data']:
            print("âŒ Match details bulunamadÄ±")
            return {}
        
        match_details = self.log_data['response_data']['matchDetails']
        
        print(f"ğŸ“Š Algoritma KullanÄ±m DaÄŸÄ±lÄ±mÄ±:")
        total_matches = sum(detail['count'] for detail in match_details.values())
        
        for algo_name, details in match_details.items():
            count = details['count']
            percentage = (count / total_matches) * 100 if total_matches > 0 else 0
            avg_time = details['time'] / count if count > 0 else 0
            print(f"   {algo_name}: {count} eÅŸleÅŸme (%{percentage:.1f}) - Ort. sÃ¼re: {avg_time:.1f}ms")
        
        # Performans istatistikleri
        execution_time = self.log_data['response_data']['executionTime']
        total_processed = self.log_data['response_data']['totalProcessed']
        avg_process_time = self.log_data['response_data']['averageProcessTime']
        
        print(f"\nâ±ï¸  Performans Ä°statistikleri:")
        print(f"   Toplam iÅŸlem sÃ¼resi: {execution_time}ms ({execution_time/1000:.1f}s)")
        print(f"   Ä°ÅŸlenen dosya sayÄ±sÄ±: {total_processed}")
        print(f"   Ortalama iÅŸlem sÃ¼resi: {avg_process_time}ms")
        print(f"   Dosya baÅŸÄ±na sÃ¼re: {execution_time/total_processed:.1f}ms")
        
        self.analysis_results['algorithm_performance'] = {
            'match_details': match_details,
            'execution_time': execution_time,
            'total_processed': total_processed,
            'avg_process_time': avg_process_time
        }
        
        return self.analysis_results['algorithm_performance']
    
    def generate_similarity_recommendations(self):
        """Benzerlik algoritmasÄ± iÃ§in Ã¶neriler oluÅŸtur"""
        print("\nğŸ’¡ BENZERLÄ°K ALGORÄ°TMASI Ã–NERÄ°LERÄ°")
        print("=" * 60)
        
        recommendations = []
        
        # Problemli eÅŸleÅŸme analizi
        if 'problematic_analysis' in self.analysis_results:
            problematic = self.analysis_results['problematic_analysis']
            problematic_count = len(problematic['problematic_matches'])
            low_quality_count = len(problematic['low_quality_matches'])
            general_word_count = len(problematic['general_word_matches'])
            
            # Threshold Ã¶nerisi
            if problematic_count > 0:
                recommendations.append({
                    'priority': 'HIGH',
                    'category': 'Threshold',
                    'issue': f'{problematic_count} adet dÃ¼ÅŸÃ¼k benzerlik eÅŸleÅŸmesi (< 0.7)',
                    'solution': 'Threshold deÄŸerini 0.75-0.8 arasÄ±na yÃ¼kseltin',
                    'code': 'threshold = 0.75  # 0.4 yerine',
                    'impact': f'Bu deÄŸiÅŸiklik {problematic_count} mantÄ±ksÄ±z eÅŸleÅŸmeyi engelleyecek'
                })
            
            # Genel kelime filtresi Ã¶nerisi
            if general_word_count > 0:
                recommendations.append({
                    'priority': 'HIGH',
                    'category': 'General Word Filter',
                    'issue': f'{general_word_count} adet genel kelime baÄŸÄ±mlÄ± eÅŸleÅŸme',
                    'solution': 'Genel kelimeleri filtreleyin',
                    'code': '''common_words = {'remix', 'mix', 'dj', 'feat', 'ft', 'music', 'song', 'mp3', 'm4a', 'flac', 'wmv', 'the', 'a', 'an', 'and', 'or', 'of', 'in', 'on', 'at', 'to', 'for', 'with', 'by'}
if len(exact_matches - common_words) < 2: return 0.0''',
                    'impact': f'Bu deÄŸiÅŸiklik {general_word_count} genel kelime baÄŸÄ±mlÄ± eÅŸleÅŸmeyi engelleyecek'
                })
            
            # Minimum ortak kelime Ã¶nerisi
            if low_quality_count > 0:
                recommendations.append({
                    'priority': 'MEDIUM',
                    'category': 'Quality Control',
                    'issue': f'{low_quality_count} adet dÃ¼ÅŸÃ¼k kaliteli eÅŸleÅŸme (az ortak kelime)',
                    'solution': 'Minimum ortak kelime sayÄ±sÄ± kontrolÃ¼ ekleyin',
                    'code': 'if len(common_words) < 3 and similarity < 0.9: return 0.0',
                    'impact': f'Bu deÄŸiÅŸiklik {low_quality_count} dÃ¼ÅŸÃ¼k kaliteli eÅŸleÅŸmeyi engelleyecek'
                })
        
        # Benzerlik skorlarÄ± analizi
        if 'similarity_focus' in self.analysis_results:
            similarities = self.analysis_results['similarity_focus']['similarities']
            if similarities:
                avg_similarity = statistics.mean(similarities)
                high_similarity_count = len([s for s in similarities if s >= 0.9])
                
                # Ã‡ok yÃ¼ksek benzerlik oranÄ± analizi
                if high_similarity_count > len(similarities) * 0.8:
                    recommendations.append({
                        'priority': 'LOW',
                        'category': 'Algorithm Efficiency',
                        'issue': f'Ã‡ok yÃ¼ksek benzerlik oranÄ±: %{(high_similarity_count/len(similarities))*100:.1f}',
                        'solution': 'Tam eÅŸleÅŸme algoritmalarÄ±nÄ± optimize edin',
                        'code': 'Ä°ndeks optimizasyonu ve Ã¶nbellek kullanÄ±mÄ±',
                        'impact': 'Performans artÄ±ÅŸÄ± saÄŸlayacak'
                    })
        
        # Kelime aÄŸÄ±rlÄ±klandÄ±rmasÄ± Ã¶nerisi
        recommendations.append({
            'priority': 'MEDIUM',
            'category': 'Scoring Algorithm',
            'issue': 'KÄ±smi eÅŸleÅŸme Ã§ok kolay (sadece 3+ karakter)',
            'solution': 'Kelime aÄŸÄ±rlÄ±klandÄ±rmasÄ±nÄ± dÃ¼zeltin',
            'code': '''# Tam eÅŸleÅŸme: %95, KÄ±smi eÅŸleÅŸme: %5
file_score = (exact_file_score * 0.95) + (partial_file_score * 0.05)

# Minimum kelime uzunluÄŸu artÄ±r
if len(search_word) > 4 and len(target_word) > 4:''',
            'impact': 'Daha kaliteli eÅŸleÅŸmeler saÄŸlayacak'
        })
        
        # Ã–nerileri yazdÄ±r
        for i, rec in enumerate(recommendations, 1):
            priority_color = "ğŸ”´" if rec['priority'] == 'HIGH' else "ğŸŸ¡" if rec['priority'] == 'MEDIUM' else "ğŸŸ¢"
            print(f"\n{i}. {priority_color} {rec['category']} - {rec['priority']} Ã–ncelik")
            print(f"   Sorun: {rec['issue']}")
            print(f"   Ã‡Ã¶zÃ¼m: {rec['solution']}")
            print(f"   Etki: {rec['impact']}")
            print(f"   Kod:")
            for line in rec['code'].split('\n'):
                print(f"     {line}")
        
        self.analysis_results['similarity_recommendations'] = recommendations
        return recommendations
    
    def save_analysis_report(self, output_file: str = None):
        """Analiz raporunu kaydet"""
        if not output_file:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            output_file = f"similarity_analysis_report_{timestamp}.json"
        
        report = {
            'timestamp': datetime.now().isoformat(),
            'log_file': self.log_file_path,
            'db_file': self.db_file_path,
            'analysis_results': self.analysis_results
        }
        
        try:
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(report, f, ensure_ascii=False, indent=2)
            print(f"\nğŸ’¾ Analiz raporu kaydedildi: {output_file}")
            return output_file
        except Exception as e:
            print(f"âŒ Rapor kaydedilemedi: {e}")
            return None
    
    def run_similarity_focused_analysis(self):
        """Benzerlik algoritmasÄ± odaklÄ± analizi Ã§alÄ±ÅŸtÄ±r"""
        print("ğŸš€ BENZERLÄ°K ALGORÄ°TMASI ODAKLI ANALÄ°Z SÄ°STEMÄ°")
        print("=" * 80)
        
        if not self.load_data():
            return False
        
        # Sadece benzerlik algoritmasÄ± ile ilgili analizleri Ã§alÄ±ÅŸtÄ±r
        self.analyze_similarity_algorithm_focus()
        self.analyze_problematic_matches()
        self.generate_similarity_recommendations()
        
        # Raporu kaydet
        report_file = self.save_analysis_report()
        
        print(f"\nâœ… Benzerlik algoritmasÄ± analizi tamamlandÄ±!")
        if report_file:
            print(f"ğŸ“„ DetaylÄ± rapor: {report_file}")
        
        return True

def main():
    """Ana fonksiyon"""
    # Dosya yollarÄ±
    log_file = "py/logs/search_files_log_20250913_124818.json"
    db_file = "py/musicfiles.db.json"
    
    # Analiz sistemini baÅŸlat
    analyzer = SimilarityDetailedAnalysisSystem(log_file, db_file)
    
    # Benzerlik algoritmasÄ± odaklÄ± analizi Ã§alÄ±ÅŸtÄ±r
    success = analyzer.run_similarity_focused_analysis()
    
    if success:
        print("\nğŸ¯ Benzerlik algoritmasÄ± analizi baÅŸarÄ±yla tamamlandÄ±!")
    else:
        print("\nâŒ Analiz sÄ±rasÄ±nda hata oluÅŸtu!")

if __name__ == "__main__":
    main()

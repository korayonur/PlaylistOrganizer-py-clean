#!/usr/bin/env python3
"""
KapsamlÄ± Benzerlik Analiz Sistemi
=================================

Bu sistem ÅŸu analizleri yapar:
1. Log dosyasÄ±ndaki TÃœM eÅŸleÅŸmeleri detaylÄ± analiz eder
2. VeritabanÄ±ndaki dosyalarÄ± analiz eder
3. Neden bulamadÄ±ÄŸÄ±nÄ± veya yanlÄ±ÅŸ bulduÄŸunu tespit eder
4. Her eÅŸleÅŸme iÃ§in detaylÄ± rapor oluÅŸturur
5. Algoritma sorunlarÄ±nÄ± netleÅŸtirir
"""

import json
import re
import os
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Tuple, Any, Set
from collections import Counter, defaultdict
import statistics

class ComprehensiveSimilarityAnalysis:
    def __init__(self, log_file_path: str, db_file_path: str):
        self.log_file_path = log_file_path
        self.db_file_path = db_file_path
        self.log_data = None
        self.db_data = None
        self.db_files = {}  # path -> file_info mapping
        self.analysis_results = {}
        
    def load_data(self):
        """Verileri yÃ¼kle ve indeksle"""
        print("ğŸ“ Veriler yÃ¼kleniyor ve indeksleniyor...")
        
        # Log dosyasÄ±nÄ± yÃ¼kle
        try:
            with open(self.log_file_path, 'r', encoding='utf-8') as f:
                self.log_data = json.load(f)
            print(f"âœ… Log dosyasÄ± yÃ¼klendi: {len(self.log_data['response_data']['results'])} sonuÃ§")
        except Exception as e:
            print(f"âŒ Log dosyasÄ± yÃ¼klenemedi: {e}")
            return False
            
        # VeritabanÄ±nÄ± yÃ¼kle ve indeksle
        try:
            with open(self.db_file_path, 'r', encoding='utf-8') as f:
                self.db_data = json.load(f)
            
            # VeritabanÄ± dosyalarÄ±nÄ± indeksle
            self.db_files = {}
            for file_info in self.db_data.get('musicFiles', []):
                if 'path' in file_info:
                    self.db_files[file_info['path']] = file_info
            
            print(f"âœ… VeritabanÄ± yÃ¼klendi: {len(self.db_files)} dosya indekslendi")
        except Exception as e:
            print(f"âŒ VeritabanÄ± yÃ¼klenemedi: {e}")
            return False
            
        return True
    
    def analyze_all_matches(self):
        """TÃœM eÅŸleÅŸmeleri detaylÄ± analiz et"""
        print("\nğŸ” TÃœM EÅLEÅMELER DETAYLI ANALÄ°ZÄ°")
        print("=" * 80)
        
        results = self.log_data['response_data']['results']
        total_results = len(results)
        
        # Kategorilere ayÄ±r
        exact_matches = []
        similar_matches = []
        not_found = []
        
        for result in results:
            if result.get('found'):
                if result.get('matchType') == 'benzerDosya':
                    similar_matches.append(result)
                else:
                    exact_matches.append(result)
            else:
                not_found.append(result)
        
        print(f"ğŸ“Š EÅŸleÅŸme Kategorileri:")
        print(f"   Tam eÅŸleÅŸme: {len(exact_matches)}")
        print(f"   Benzerlik eÅŸleÅŸmesi: {len(similar_matches)}")
        print(f"   Bulunamayan: {len(not_found)}")
        print(f"   Toplam: {total_results}")
        
        # Her kategoriyi detaylÄ± analiz et
        self.analyze_exact_matches(exact_matches)
        self.analyze_similar_matches(similar_matches)
        self.analyze_not_found(not_found)
        
        return {
            'exact_matches': exact_matches,
            'similar_matches': similar_matches,
            'not_found': not_found
        }
    
    def analyze_exact_matches(self, exact_matches: List[Dict]):
        """Tam eÅŸleÅŸmeleri analiz et"""
        print(f"\nâœ… TAM EÅLEÅMELER ANALÄ°ZÄ° ({len(exact_matches)} adet)")
        print("-" * 60)
        
        if not exact_matches:
            print("   Tam eÅŸleÅŸme bulunamadÄ±")
            return
        
        # Algoritma tÃ¼rlerine gÃ¶re grupla
        algorithm_groups = defaultdict(list)
        for match in exact_matches:
            algo = match.get('matchType', 'unknown')
            algorithm_groups[algo].append(match)
        
        for algo, matches in algorithm_groups.items():
            print(f"\n   {algo}: {len(matches)} eÅŸleÅŸme")
            for i, match in enumerate(matches[:3]):  # Ä°lk 3 Ã¶rnek
                original = match['originalPath'].split('/')[-1]
                found = match['foundPath'].split('/')[-1]
                print(f"     {i+1}. {original} â†’ {found}")
    
    def analyze_similar_matches(self, similar_matches: List[Dict]):
        """Benzerlik eÅŸleÅŸmelerini detaylÄ± analiz et"""
        print(f"\nğŸ¯ BENZERLÄ°K EÅLEÅMELERÄ° DETAYLI ANALÄ°ZÄ° ({len(similar_matches)} adet)")
        print("-" * 60)
        
        if not similar_matches:
            print("   Benzerlik eÅŸleÅŸmesi bulunamadÄ±")
            return
        
        # Benzerlik skorlarÄ±na gÃ¶re grupla
        score_groups = {
            'excellent': [],  # 0.9-1.0
            'good': [],       # 0.7-0.9
            'poor': [],       # 0.5-0.7
            'terrible': []    # 0.0-0.5
        }
        
        for match in similar_matches:
            similarity = match.get('similarity', 0)
            if similarity >= 0.9:
                score_groups['excellent'].append(match)
            elif similarity >= 0.7:
                score_groups['good'].append(match)
            elif similarity >= 0.5:
                score_groups['poor'].append(match)
            else:
                score_groups['terrible'].append(match)
        
        for group_name, matches in score_groups.items():
            if matches:
                print(f"\n   {group_name.upper()} ({len(matches)} adet):")
                for i, match in enumerate(matches[:5]):  # Ä°lk 5 Ã¶rnek
                    self.analyze_single_match(match, i+1)
    
    def analyze_single_match(self, match: Dict, index: int):
        """Tek bir eÅŸleÅŸmeyi detaylÄ± analiz et"""
        original_path = match['originalPath']
        found_path = match['foundPath']
        similarity = match.get('similarity', 0)
        
        original_file = original_path.split('/')[-1]
        found_file = found_path.split('/')[-1]
        
        print(f"\n     {index}. BENZERLÄ°K: {similarity:.3f}")
        print(f"        Orijinal: {original_file}")
        print(f"        Bulunan:  {found_file}")
        
        # Kelime analizi
        orig_words = set(re.findall(r'[a-zA-ZÃ§ÄŸÄ±Ã¶ÅŸÃ¼Ã‡ÄIÄ°Ã–ÅÃœ]+', original_file.lower()))
        found_words = set(re.findall(r'[a-zA-ZÃ§ÄŸÄ±Ã¶ÅŸÃ¼Ã‡ÄIÄ°Ã–ÅÃœ]+', found_file.lower()))
        common_words = orig_words & found_words
        
        print(f"        Ortak kelimeler: {list(common_words)} ({len(common_words)} adet)")
        
        # Genel kelime analizi
        general_words = {'remix', 'mix', 'dj', 'feat', 'ft', 'music', 'song', 'mp3', 'm4a', 'flac', 'wmv', 'the', 'a', 'an', 'and', 'or', 'of', 'in', 'on', 'at', 'to', 'for', 'with', 'by'}
        non_general_words = common_words - general_words
        
        print(f"        Genel olmayan kelimeler: {list(non_general_words)} ({len(non_general_words)} adet)")
        
        # VeritabanÄ±nda kontrol et
        self.check_database_match(original_path, found_path)
        
        # Sorun tespiti
        issues = self.detect_match_issues(match, common_words, non_general_words)
        if issues:
            print(f"        âš ï¸  SORUNLAR: {', '.join(issues)}")
    
    def check_database_match(self, original_path: str, found_path: str):
        """VeritabanÄ±nda dosyalarÄ± kontrol et"""
        original_in_db = original_path in self.db_files
        found_in_db = found_path in self.db_files
        
        print(f"        VeritabanÄ± kontrolÃ¼:")
        print(f"          Orijinal dosya: {'âœ… Var' if original_in_db else 'âŒ Yok'}")
        print(f"          Bulunan dosya:  {'âœ… Var' if found_in_db else 'âŒ Yok'}")
        
        if not found_in_db:
            print(f"          âš ï¸  Bulunan dosya veritabanÄ±nda yok!")
    
    def detect_match_issues(self, match: Dict, common_words: Set[str], non_general_words: Set[str]) -> List[str]:
        """EÅŸleÅŸme sorunlarÄ±nÄ± tespit et"""
        issues = []
        similarity = match.get('similarity', 0)
        
        # DÃ¼ÅŸÃ¼k benzerlik
        if similarity < 0.7:
            issues.append(f"DÃ¼ÅŸÃ¼k benzerlik ({similarity:.3f})")
        
        # Az ortak kelime
        if len(common_words) < 3 and similarity < 0.9:
            issues.append(f"Az ortak kelime ({len(common_words)})")
        
        # Genel kelime baÄŸÄ±mlÄ±
        if len(non_general_words) < 2 and similarity < 0.9:
            issues.append(f"Genel kelime baÄŸÄ±mlÄ± ({len(non_general_words)} anlamlÄ± kelime)")
        
        # Sadece 1 anlamlÄ± kelime
        if len(non_general_words) == 1 and similarity < 0.9:
            issues.append("Sadece 1 anlamlÄ± kelime")
        
        return issues
    
    def analyze_not_found(self, not_found: List[Dict]):
        """Bulunamayan dosyalarÄ± analiz et"""
        print(f"\nâŒ BULUNAMADAN DOSYALAR ANALÄ°ZÄ° ({len(not_found)} adet)")
        print("-" * 60)
        
        if not not_found:
            print("   TÃ¼m dosyalar bulundu")
            return
        
        # VeritabanÄ±nda var mÄ± kontrol et
        in_db_count = 0
        not_in_db_count = 0
        
        for match in not_found:
            original_path = match['originalPath']
            if original_path in self.db_files:
                in_db_count += 1
            else:
                not_in_db_count += 1
        
        print(f"   VeritabanÄ±nda var: {in_db_count}")
        print(f"   VeritabanÄ±nda yok: {not_in_db_count}")
        
        # VeritabanÄ±nda olan ama bulunamayan dosyalarÄ± analiz et
        if in_db_count > 0:
            print(f"\n   VeritabanÄ±nda olan ama bulunamayan dosyalar:")
            for i, match in enumerate(not_found[:10]):  # Ä°lk 10 Ã¶rnek
                original_path = match['originalPath']
                if original_path in self.db_files:
                    original_file = original_path.split('/')[-1]
                    print(f"     {i+1}. {original_file}")
                    self.analyze_why_not_found(original_path)
    
    def analyze_why_not_found(self, original_path: str):
        """Neden bulunamadÄ±ÄŸÄ±nÄ± analiz et"""
        if original_path not in self.db_files:
            print(f"        âŒ Dosya veritabanÄ±nda yok")
            return
        
        file_info = self.db_files[original_path]
        original_file = original_path.split('/')[-1]
        
        print(f"        ğŸ” Neden bulunamadÄ± analizi:")
        
        # Dosya adÄ± analizi
        orig_words = set(re.findall(r'[a-zA-ZÃ§ÄŸÄ±Ã¶ÅŸÃ¼Ã‡ÄIÄ°Ã–ÅÃœ]+', original_file.lower()))
        print(f"          Dosya adÄ± kelimeleri: {list(orig_words)}")
        
        # VeritabanÄ±ndaki kelimeler
        if 'fileWords' in file_info:
            db_words = set(file_info['fileWords'])
            print(f"          VeritabanÄ± kelimeleri: {list(db_words)}")
            
            # Ortak kelime analizi
            common_words = orig_words & db_words
            print(f"          Ortak kelimeler: {list(common_words)} ({len(common_words)} adet)")
        
        # Benzer dosyalar ara
        similar_files = self.find_similar_files_in_db(original_file)
        if similar_files:
            print(f"          Benzer dosyalar bulundu:")
            for similar_file, similarity in similar_files[:3]:
                print(f"            {similar_file} (benzerlik: {similarity:.3f})")
    
    def find_similar_files_in_db(self, target_file: str) -> List[Tuple[str, float]]:
        """VeritabanÄ±nda benzer dosyalar ara"""
        target_words = set(re.findall(r'[a-zA-ZÃ§ÄŸÄ±Ã¶ÅŸÃ¼Ã‡ÄIÄ°Ã–ÅÃœ]+', target_file.lower()))
        similar_files = []
        
        for db_path, file_info in self.db_files.items():
            if 'fileWords' in file_info:
                db_words = set(file_info['fileWords'])
                common_words = target_words & db_words
                
                if common_words:
                    similarity = len(common_words) / len(target_words) if target_words else 0
                    if similarity > 0.3:  # En az %30 benzerlik
                        similar_files.append((db_path.split('/')[-1], similarity))
        
        # Benzerlik skoruna gÃ¶re sÄ±rala
        similar_files.sort(key=lambda x: x[1], reverse=True)
        return similar_files
    
    def analyze_database_coverage(self):
        """VeritabanÄ± kapsamÄ±nÄ± analiz et"""
        print(f"\nğŸ—„ï¸  VERÄ°TABANI KAPSAM ANALÄ°ZÄ°")
        print("=" * 60)
        
        # Log dosyasÄ±ndaki tÃ¼m dosyalarÄ± al
        log_files = set()
        for result in self.log_data['response_data']['results']:
            log_files.add(result['originalPath'])
        
        # VeritabanÄ±nda olan/olmayan dosyalarÄ± say
        in_db = 0
        not_in_db = 0
        
        for log_file in log_files:
            if log_file in self.db_files:
                in_db += 1
            else:
                not_in_db += 1
        
        print(f"ğŸ“Š VeritabanÄ± KapsamÄ±:")
        print(f"   Log dosyasÄ±ndaki dosyalar: {len(log_files)}")
        print(f"   VeritabanÄ±nda var: {in_db} (%{(in_db/len(log_files))*100:.1f})")
        print(f"   VeritabanÄ±nda yok: {not_in_db} (%{(not_in_db/len(log_files))*100:.1f})")
        
        # VeritabanÄ±nda olmayan dosyalarÄ± gÃ¶ster
        if not_in_db > 0:
            print(f"\n   VeritabanÄ±nda olmayan dosyalar:")
            missing_files = [f for f in log_files if f not in self.db_files]
            for i, missing_file in enumerate(missing_files[:10]):  # Ä°lk 10 Ã¶rnek
                print(f"     {i+1}. {missing_file.split('/')[-1]}")
    
    def generate_comprehensive_report(self):
        """KapsamlÄ± rapor oluÅŸtur"""
        print(f"\nğŸ“‹ KAPSAMLI RAPOR OLUÅTURULUYOR")
        print("=" * 60)
        
        # TÃ¼m analizleri Ã§alÄ±ÅŸtÄ±r
        matches_analysis = self.analyze_all_matches()
        self.analyze_database_coverage()
        
        # Ã–zet istatistikler
        total_results = len(self.log_data['response_data']['results'])
        found_results = len([r for r in self.log_data['response_data']['results'] if r.get('found')])
        not_found_results = total_results - found_results
        
        print(f"\nğŸ“Š Ã–ZET Ä°STATÄ°STÄ°KLER:")
        print(f"   Toplam dosya: {total_results}")
        print(f"   Bulunan: {found_results} (%{(found_results/total_results)*100:.1f})")
        print(f"   Bulunamayan: {not_found_results} (%{(not_found_results/total_results)*100:.1f})")
        
        # Benzerlik eÅŸleÅŸmeleri analizi
        similar_matches = matches_analysis['similar_matches']
        if similar_matches:
            similarities = [m.get('similarity', 0) for m in similar_matches]
            print(f"\n   Benzerlik eÅŸleÅŸmeleri: {len(similar_matches)}")
            print(f"   Ortalama benzerlik: {statistics.mean(similarities):.3f}")
            print(f"   En dÃ¼ÅŸÃ¼k benzerlik: {min(similarities):.3f}")
            print(f"   En yÃ¼ksek benzerlik: {max(similarities):.3f}")
            
            # Problemli eÅŸleÅŸmeler
            problematic = [m for m in similar_matches if m.get('similarity', 0) < 0.7]
            print(f"   Problemli eÅŸleÅŸmeler (< 0.7): {len(problematic)}")
        
        # Raporu kaydet
        self.save_comprehensive_report()
    
    def save_comprehensive_report(self):
        """KapsamlÄ± raporu kaydet"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        report_file = f"comprehensive_similarity_report_{timestamp}.json"
        
        # Rapor verilerini hazÄ±rla
        report_data = {
            'timestamp': datetime.now().isoformat(),
            'log_file': self.log_file_path,
            'db_file': self.db_file_path,
            'summary': {
                'total_files': len(self.log_data['response_data']['results']),
                'found_files': len([r for r in self.log_data['response_data']['results'] if r.get('found')]),
                'not_found_files': len([r for r in self.log_data['response_data']['results'] if not r.get('found')])
            },
            'analysis_results': self.analysis_results
        }
        
        try:
            with open(report_file, 'w', encoding='utf-8') as f:
                json.dump(report_data, f, ensure_ascii=False, indent=2)
            print(f"\nğŸ’¾ KapsamlÄ± rapor kaydedildi: {report_file}")
            return report_file
        except Exception as e:
            print(f"âŒ Rapor kaydedilemedi: {e}")
            return None
    
    def run_comprehensive_analysis(self):
        """KapsamlÄ± analizi Ã§alÄ±ÅŸtÄ±r"""
        print("ğŸš€ KAPSAMLI BENZERLÄ°K ANALÄ°Z SÄ°STEMÄ°")
        print("=" * 80)
        
        if not self.load_data():
            return False
        
        # KapsamlÄ± analizi Ã§alÄ±ÅŸtÄ±r
        self.generate_comprehensive_report()
        
        print(f"\nâœ… KapsamlÄ± analiz tamamlandÄ±!")
        
        return True

def main():
    """Ana fonksiyon"""
    # Dosya yollarÄ±
    log_file = "py/logs/search_files_log_20250913_124818.json"
    db_file = "py/musicfiles.db.json"
    
    # Analiz sistemini baÅŸlat
    analyzer = ComprehensiveSimilarityAnalysis(log_file, db_file)
    
    # KapsamlÄ± analizi Ã§alÄ±ÅŸtÄ±r
    success = analyzer.run_comprehensive_analysis()
    
    if success:
        print("\nğŸ¯ KapsamlÄ± analiz baÅŸarÄ±yla tamamlandÄ±!")
    else:
        print("\nâŒ Analiz sÄ±rasÄ±nda hata oluÅŸtu!")

if __name__ == "__main__":
    main()

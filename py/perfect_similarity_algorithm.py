#!/usr/bin/env python3
"""
MÃ¼kemmel Benzerlik AlgoritmasÄ± ve KarÅŸÄ±laÅŸtÄ±rma Sistemi
======================================================

Bu sistem:
1. Mevcut algoritmanÄ±n sorunlarÄ±nÄ± analiz eder
2. Yeni mÃ¼kemmel algoritma geliÅŸtirir
3. Ä°ki algoritmayÄ± karÅŸÄ±laÅŸtÄ±rÄ±r
4. DetaylÄ± rapor oluÅŸturur
"""

import json
import re
import os
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Tuple, Any, Set
from collections import Counter, defaultdict
import statistics

class PerfectSimilarityAlgorithm:
    def __init__(self, log_file_path: str, db_file_path: str):
        self.log_file_path = log_file_path
        self.db_file_path = db_file_path
        self.log_data = None
        self.db_data = None
        self.db_files = {}
        self.analysis_results = {}
        
        # Genel kelimeler (filtreleme iÃ§in)
        self.common_words = {
            'remix', 'mix', 'dj', 'feat', 'ft', 'music', 'song', 'mp3', 'm4a', 'flac', 'wmv',
            'the', 'a', 'an', 'and', 'or', 'of', 'in', 'on', 'at', 'to', 'for', 'with', 'by',
            'official', 'video', 'hd', 'version', 'edit', 'extended', 'radio', 'clean',
            'original', 'acoustic', 'live', 'studio', 'album', 'single', 'ep', 'lp'
        }
        
        # TÃ¼rkÃ§e genel kelimeler
        self.turkish_common_words = {
            've', 'ile', 'iÃ§in', 'olan', 'olan', 'gibi', 'kadar', 'sonra', 'Ã¶nce',
            'mÃ¼zik', 'ÅŸarkÄ±', 'parÃ§a', 'remix', 'mix', 'dj', 'feat', 'ft'
        }
        
        # TÃ¼m genel kelimeleri birleÅŸtir
        self.all_common_words = self.common_words | self.turkish_common_words
    
    def load_data(self):
        """Verileri yÃ¼kle"""
        print("ğŸ“ Veriler yÃ¼kleniyor...")
        
        try:
            with open(self.log_file_path, 'r', encoding='utf-8') as f:
                self.log_data = json.load(f)
            print(f"âœ… Log dosyasÄ± yÃ¼klendi: {len(self.log_data['response_data']['results'])} sonuÃ§")
        except Exception as e:
            print(f"âŒ Log dosyasÄ± yÃ¼klenemedi: {e}")
            return False
            
        try:
            with open(self.db_file_path, 'r', encoding='utf-8') as f:
                self.db_data = json.load(f)
            
            self.db_files = {}
            for file_info in self.db_data.get('musicFiles', []):
                if 'path' in file_info:
                    self.db_files[file_info['path']] = file_info
            
            print(f"âœ… VeritabanÄ± yÃ¼klendi: {len(self.db_files)} dosya")
        except Exception as e:
            print(f"âŒ VeritabanÄ± yÃ¼klenemedi: {e}")
            return False
            
        return True
    
    def normalize_text(self, text: str) -> str:
        """Metni normalize et"""
        if not text:
            return ""
        
        # KÃ¼Ã§Ã¼k harfe Ã§evir
        text = text.lower()
        
        # TÃ¼rkÃ§e karakterleri dÃ¶nÃ¼ÅŸtÃ¼r
        char_map = {
            'Ã§': 'c', 'ÄŸ': 'g', 'Ä±': 'i', 'Ã¶': 'o', 'ÅŸ': 's', 'Ã¼': 'u',
            'Ã‡': 'c', 'Ä': 'g', 'Ä°': 'i', 'Ã–': 'o', 'Å': 's', 'Ãœ': 'u'
        }
        
        for tr_char, en_char in char_map.items():
            text = text.replace(tr_char, en_char)
        
        # Sadece harf ve rakam bÄ±rak
        text = re.sub(r'[^a-z0-9\s]', ' ', text)
        
        # Ã‡oklu boÅŸluklarÄ± tek boÅŸluÄŸa Ã§evir
        text = re.sub(r'\s+', ' ', text)
        
        return text.strip()
    
    def extract_words(self, text: str) -> List[str]:
        """Metinden kelimeleri Ã§Ä±kar"""
        normalized = self.normalize_text(text)
        words = [word for word in normalized.split() if len(word) > 1]
        return words
    
    def calculate_old_similarity(self, words1: List[str], words2: List[str]) -> float:
        """ESKÄ° ALGORÄ°TMA - Mevcut algoritmanÄ±n simÃ¼lasyonu"""
        if not words1 or not words2:
            return 0.0
        
        # Tam kelime eÅŸleÅŸmesi
        exact_matches = sum(1 for word in words1 if word in words2)
        
        # Hibrit normalizasyon
        min_length = min(len(words1), len(words2))
        max_length = max(len(words1), len(words2))
        
        if max_length > min_length * 3:
            exact_match_score = exact_matches / min_length if min_length > 0 else 0.0
        else:
            exact_match_score = exact_matches / max_length if max_length > 0 else 0.0
        
        # KÄ±smi kelime eÅŸleÅŸmesi
        partial_matches = sum(
            1
            for word in words1
            if any((len(word) > 3 and word in w) or (len(w) > 3 and w in word) for w in words2)
        )
        partial_match_score = partial_matches / max_length if max_length > 0 else 0.0
        
        return (exact_match_score * 0.85) + (partial_match_score * 0.15)
    
    def calculate_perfect_similarity(self, words1: List[str], words2: List[str]) -> float:
        """YENÄ° MÃœKEMMEL ALGORÄ°TMA"""
        if not words1 or not words2:
            return 0.0
        
        # 1. GENEL KELÄ°ME FÄ°LTRESÄ°
        meaningful_words1 = [w for w in words1 if w not in self.all_common_words]
        meaningful_words2 = [w for w in words2 if w not in self.all_common_words]
        
        # EÄŸer anlamlÄ± kelime yoksa, genel kelimeleri kullan ama dÃ¼ÅŸÃ¼k skor ver
        if not meaningful_words1 or not meaningful_words2:
            if not words1 or not words2:
                return 0.0
            # Sadece genel kelimeler varsa Ã§ok dÃ¼ÅŸÃ¼k skor
            exact_matches = sum(1 for word in words1 if word in words2)
            return (exact_matches / max(len(words1), len(words2))) * 0.3
        
        # 2. ANLAMLI KELÄ°ME EÅLEÅMESÄ° (Ana skor)
        exact_meaningful_matches = sum(1 for word in meaningful_words1 if word in meaningful_words2)
        meaningful_score = exact_meaningful_matches / max(len(meaningful_words1), len(meaningful_words2))
        
        # 3. KELÄ°ME UZUNLUK BONUSU (Uzun kelimeler daha Ã¶nemli)
        long_word_matches = sum(1 for word in meaningful_words1 if word in meaningful_words2 and len(word) >= 4)
        long_word_bonus = long_word_matches / max(len(meaningful_words1), len(meaningful_words2)) * 0.2
        
        # 4. SANATÃ‡I ADI BONUSU (Ä°lk kelime)
        artist_bonus = 0.0
        if meaningful_words1 and meaningful_words2:
            if meaningful_words1[0] == meaningful_words2[0] and len(meaningful_words1[0]) >= 3:
                artist_bonus = 0.3
        
        # 5. ÅARKI ADI BONUSU (Ä°kinci kelime)
        song_bonus = 0.0
        if len(meaningful_words1) >= 2 and len(meaningful_words2) >= 2:
            if meaningful_words1[1] == meaningful_words2[1] and len(meaningful_words1[1]) >= 3:
                song_bonus = 0.2
        
        # 6. TAM EÅLEÅME BONUSU
        full_match_bonus = 0.0
        if exact_meaningful_matches >= 3:
            full_match_bonus = 0.15
        
        # 7. GENEL KELÄ°ME PENALTY
        general_word_penalty = 0.0
        general_matches = sum(1 for word in words1 if word in words2 and word in self.all_common_words)
        if general_matches > 0:
            general_word_penalty = min(0.2, general_matches * 0.05)
        
        # Toplam skor hesapla
        total_score = meaningful_score + long_word_bonus + artist_bonus + song_bonus + full_match_bonus - general_word_penalty
        
        # 0.0 - 1.0 arasÄ±nda sÄ±nÄ±rla
        return max(0.0, min(1.0, total_score))
    
    def analyze_old_algorithm_problems(self):
        """Eski algoritmanÄ±n sorunlarÄ±nÄ± analiz et"""
        print("\nğŸ” ESKÄ° ALGORÄ°TMA SORUNLARI ANALÄ°ZÄ°")
        print("=" * 60)
        
        results = self.log_data['response_data']['results']
        similar_matches = [r for r in results if r.get('found') and r.get('matchType') == 'benzerDosya']
        
        problems = {
            'low_similarity': [],
            'common_word_dependent': [],
            'single_word_matches': [],
            'meaningless_matches': []
        }
        
        for match in similar_matches:
            original_file = match['originalPath'].split('/')[-1]
            found_file = match['foundPath'].split('/')[-1]
            similarity = match.get('similarity', 0)
            
            orig_words = self.extract_words(original_file)
            found_words = self.extract_words(found_file)
            common_words = set(orig_words) & set(found_words)
            meaningful_common = common_words - self.all_common_words
            
            # DÃ¼ÅŸÃ¼k benzerlik
            if similarity < 0.7:
                problems['low_similarity'].append({
                    'original': original_file,
                    'found': found_file,
                    'similarity': similarity,
                    'common_words': list(common_words),
                    'meaningful_words': list(meaningful_common)
                })
            
            # Genel kelime baÄŸÄ±mlÄ±
            if len(meaningful_common) < 2 and similarity < 0.9:
                problems['common_word_dependent'].append({
                    'original': original_file,
                    'found': found_file,
                    'similarity': similarity,
                    'common_words': list(common_words),
                    'meaningful_words': list(meaningful_common)
                })
            
            # Tek kelime eÅŸleÅŸmesi
            if len(meaningful_common) == 1 and similarity < 0.9:
                problems['single_word_matches'].append({
                    'original': original_file,
                    'found': found_file,
                    'similarity': similarity,
                    'common_words': list(common_words),
                    'meaningful_words': list(meaningful_common)
                })
            
            # AnlamsÄ±z eÅŸleÅŸmeler
            if len(meaningful_common) == 0 and similarity > 0.5:
                problems['meaningless_matches'].append({
                    'original': original_file,
                    'found': found_file,
                    'similarity': similarity,
                    'common_words': list(common_words),
                    'meaningful_words': list(meaningful_common)
                })
        
        print(f"ğŸ“Š Sorun Kategorileri:")
        print(f"   DÃ¼ÅŸÃ¼k benzerlik (< 0.7): {len(problems['low_similarity'])}")
        print(f"   Genel kelime baÄŸÄ±mlÄ±: {len(problems['common_word_dependent'])}")
        print(f"   Tek kelime eÅŸleÅŸmesi: {len(problems['single_word_matches'])}")
        print(f"   AnlamsÄ±z eÅŸleÅŸmeler: {len(problems['meaningless_matches'])}")
        
        # Ã–rnekler gÃ¶ster
        for category, items in problems.items():
            if items:
                print(f"\n   {category.upper()} Ã–rnekleri:")
                for i, item in enumerate(items[:3]):
                    print(f"     {i+1}. {item['original']} â†’ {item['found']}")
                    print(f"        Benzerlik: {item['similarity']:.3f}")
                    print(f"        Ortak kelimeler: {item['common_words']}")
                    print(f"        AnlamlÄ± kelimeler: {item['meaningful_words']}")
        
        return problems
    
    def compare_algorithms(self):
        """Ä°ki algoritmayÄ± karÅŸÄ±laÅŸtÄ±r"""
        print("\nâš–ï¸  ALGORÄ°TMA KARÅILAÅTIRMASI")
        print("=" * 60)
        
        results = self.log_data['response_data']['results']
        similar_matches = [r for r in results if r.get('found') and r.get('matchType') == 'benzerDosya']
        
        comparison_results = {
            'old_scores': [],
            'new_scores': [],
            'improvements': [],
            'regressions': [],
            'statistics': {}
        }
        
        for match in similar_matches:
            original_file = match['originalPath'].split('/')[-1]
            found_file = match['foundPath'].split('/')[-1]
            old_similarity = match.get('similarity', 0)
            
            # Kelimeleri Ã§Ä±kar
            orig_words = self.extract_words(original_file)
            found_words = self.extract_words(found_file)
            
            # Yeni algoritma ile hesapla
            new_similarity = self.calculate_perfect_similarity(orig_words, found_words)
            
            comparison_results['old_scores'].append(old_similarity)
            comparison_results['new_scores'].append(new_similarity)
            
            # Ä°yileÅŸme/gerileme analizi
            diff = new_similarity - old_similarity
            if abs(diff) > 0.1:  # Ã–nemli fark
                if diff > 0:
                    comparison_results['improvements'].append({
                        'original': original_file,
                        'found': found_file,
                        'old_score': old_similarity,
                        'new_score': new_similarity,
                        'improvement': diff
                    })
                else:
                    comparison_results['regressions'].append({
                        'original': original_file,
                        'found': found_file,
                        'old_score': old_similarity,
                        'new_score': new_similarity,
                        'regression': abs(diff)
                    })
        
        # Ä°statistikler
        old_scores = comparison_results['old_scores']
        new_scores = comparison_results['new_scores']
        
        comparison_results['statistics'] = {
            'old_mean': statistics.mean(old_scores),
            'new_mean': statistics.mean(new_scores),
            'old_median': statistics.median(old_scores),
            'new_median': statistics.median(new_scores),
            'old_std': statistics.stdev(old_scores) if len(old_scores) > 1 else 0,
            'new_std': statistics.stdev(new_scores) if len(new_scores) > 1 else 0,
            'improvements_count': len(comparison_results['improvements']),
            'regressions_count': len(comparison_results['regressions']),
            'total_comparisons': len(similar_matches)
        }
        
        # SonuÃ§larÄ± yazdÄ±r
        stats = comparison_results['statistics']
        print(f"ğŸ“Š KarÅŸÄ±laÅŸtÄ±rma Ä°statistikleri:")
        print(f"   Toplam karÅŸÄ±laÅŸtÄ±rma: {stats['total_comparisons']}")
        print(f"   Ä°yileÅŸme: {stats['improvements_count']}")
        print(f"   Gerileme: {stats['regressions_count']}")
        print(f"   Eski ortalama: {stats['old_mean']:.3f}")
        print(f"   Yeni ortalama: {stats['new_mean']:.3f}")
        print(f"   Ortalama fark: {stats['new_mean'] - stats['old_mean']:.3f}")
        
        # En iyi iyileÅŸmeler
        if comparison_results['improvements']:
            print(f"\n   EN Ä°YÄ° Ä°YÄ°LEÅMELER:")
            sorted_improvements = sorted(comparison_results['improvements'], key=lambda x: x['improvement'], reverse=True)
            for i, imp in enumerate(sorted_improvements[:5]):
                print(f"     {i+1}. {imp['original']} â†’ {imp['found']}")
                print(f"        Eski: {imp['old_score']:.3f} â†’ Yeni: {imp['new_score']:.3f} (+{imp['improvement']:.3f})")
        
        # En kÃ¶tÃ¼ gerilemeler
        if comparison_results['regressions']:
            print(f"\n   EN KÃ–TÃœ GERÄ°LEMELER:")
            sorted_regressions = sorted(comparison_results['regressions'], key=lambda x: x['regression'], reverse=True)
            for i, reg in enumerate(sorted_regressions[:5]):
                print(f"     {i+1}. {reg['original']} â†’ {reg['found']}")
                print(f"        Eski: {reg['old_score']:.3f} â†’ Yeni: {reg['new_score']:.3f} (-{reg['regression']:.3f})")
        
        return comparison_results
    
    def generate_perfect_algorithm_code(self):
        """MÃ¼kemmel algoritma kodunu oluÅŸtur"""
        print("\nğŸ’» MÃœKEMMEL ALGORÄ°TMA KODU")
        print("=" * 60)
        
        code = '''
def calculate_perfect_similarity(search_words: List[str], target_words: List[str]) -> float:
    """MÃ¼kemmel benzerlik algoritmasÄ±"""
    if not search_words or not target_words:
        return 0.0
    
    # Genel kelimeler (filtreleme iÃ§in)
    common_words = {
        'remix', 'mix', 'dj', 'feat', 'ft', 'music', 'song', 'mp3', 'm4a', 'flac', 'wmv',
        'the', 'a', 'an', 'and', 'or', 'of', 'in', 'on', 'at', 'to', 'for', 'with', 'by',
        'official', 'video', 'hd', 'version', 'edit', 'extended', 'radio', 'clean',
        'original', 'acoustic', 'live', 'studio', 'album', 'single', 'ep', 'lp',
        've', 'ile', 'iÃ§in', 'olan', 'gibi', 'kadar', 'sonra', 'Ã¶nce',
        'mÃ¼zik', 'ÅŸarkÄ±', 'parÃ§a'
    }
    
    # 1. GENEL KELÄ°ME FÄ°LTRESÄ°
    meaningful_search = [w for w in search_words if w not in common_words]
    meaningful_target = [w for w in target_words if w not in common_words]
    
    # EÄŸer anlamlÄ± kelime yoksa, Ã§ok dÃ¼ÅŸÃ¼k skor ver
    if not meaningful_search or not meaningful_target:
        if not search_words or not target_words:
            return 0.0
        exact_matches = sum(1 for word in search_words if word in target_words)
        return (exact_matches / max(len(search_words), len(target_words))) * 0.3
    
    # 2. ANLAMLI KELÄ°ME EÅLEÅMESÄ° (Ana skor)
    exact_meaningful_matches = sum(1 for word in meaningful_search if word in meaningful_target)
    meaningful_score = exact_meaningful_matches / max(len(meaningful_search), len(meaningful_target))
    
    # 3. KELÄ°ME UZUNLUK BONUSU
    long_word_matches = sum(1 for word in meaningful_search if word in meaningful_target and len(word) >= 4)
    long_word_bonus = long_word_matches / max(len(meaningful_search), len(meaningful_target)) * 0.2
    
    # 4. SANATÃ‡I ADI BONUSU (Ä°lk kelime)
    artist_bonus = 0.0
    if meaningful_search and meaningful_target:
        if meaningful_search[0] == meaningful_target[0] and len(meaningful_search[0]) >= 3:
            artist_bonus = 0.3
    
    # 5. ÅARKI ADI BONUSU (Ä°kinci kelime)
    song_bonus = 0.0
    if len(meaningful_search) >= 2 and len(meaningful_target) >= 2:
        if meaningful_search[1] == meaningful_target[1] and len(meaningful_search[1]) >= 3:
            song_bonus = 0.2
    
    # 6. TAM EÅLEÅME BONUSU
    full_match_bonus = 0.0
    if exact_meaningful_matches >= 3:
        full_match_bonus = 0.15
    
    # 7. GENEL KELÄ°ME PENALTY
    general_word_penalty = 0.0
    general_matches = sum(1 for word in search_words if word in target_words and word in common_words)
    if general_matches > 0:
        general_word_penalty = min(0.2, general_matches * 0.05)
    
    # Toplam skor hesapla
    total_score = meaningful_score + long_word_bonus + artist_bonus + song_bonus + full_match_bonus - general_word_penalty
    
    # 0.0 - 1.0 arasÄ±nda sÄ±nÄ±rla
    return max(0.0, min(1.0, total_score))

# Ã–NERÄ°LEN THRESHOLD DEÄERLERÄ°:
# - MÃ¼kemmel eÅŸleÅŸme: 0.9+
# - Ã‡ok iyi eÅŸleÅŸme: 0.8-0.9
# - Ä°yi eÅŸleÅŸme: 0.7-0.8
# - Kabul edilebilir: 0.6-0.7
# - ÅÃ¼pheli: 0.5-0.6
# - Reddet: < 0.5

RECOMMENDED_THRESHOLD = 0.75  # Eski 0.4'ten yÃ¼kseltildi
'''
        
        print(code)
        return code
    
    def run_comprehensive_analysis(self):
        """KapsamlÄ± analizi Ã§alÄ±ÅŸtÄ±r"""
        print("ğŸš€ MÃœKEMMEL BENZERLÄ°K ALGORÄ°TMASI ANALÄ°ZÄ°")
        print("=" * 80)
        
        if not self.load_data():
            return False
        
        # Eski algoritma sorunlarÄ±nÄ± analiz et
        problems = self.analyze_old_algorithm_problems()
        
        # AlgoritmalarÄ± karÅŸÄ±laÅŸtÄ±r
        comparison = self.compare_algorithms()
        
        # MÃ¼kemmel algoritma kodunu oluÅŸtur
        perfect_code = self.generate_perfect_algorithm_code()
        
        # Raporu kaydet
        self.save_analysis_report(problems, comparison)
        
        print(f"\nâœ… MÃ¼kemmel algoritma analizi tamamlandÄ±!")
        
        return True
    
    def save_analysis_report(self, problems: Dict, comparison: Dict):
        """Analiz raporunu kaydet"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        report_file = f"perfect_algorithm_analysis_{timestamp}.json"
        
        report_data = {
            'timestamp': datetime.now().isoformat(),
            'analysis_type': 'perfect_similarity_algorithm',
            'old_algorithm_problems': problems,
            'algorithm_comparison': comparison,
            'recommendations': {
                'threshold': 0.75,
                'common_word_filter': True,
                'meaningful_word_minimum': 2,
                'artist_bonus': 0.3,
                'song_bonus': 0.2,
                'long_word_bonus': 0.2,
                'full_match_bonus': 0.15,
                'general_word_penalty': 0.2
            }
        }
        
        try:
            with open(report_file, 'w', encoding='utf-8') as f:
                json.dump(report_data, f, ensure_ascii=False, indent=2)
            print(f"\nğŸ’¾ Analiz raporu kaydedildi: {report_file}")
        except Exception as e:
            print(f"âŒ Rapor kaydedilemedi: {e}")

def main():
    """Ana fonksiyon"""
    log_file = "../logs/search_files_log_20250913_133024.json"
    db_file = "musicfiles.db.json"
    
    analyzer = PerfectSimilarityAlgorithm(log_file, db_file)
    success = analyzer.run_comprehensive_analysis()
    
    if success:
        print("\nğŸ¯ MÃ¼kemmel algoritma analizi baÅŸarÄ±yla tamamlandÄ±!")
    else:
        print("\nâŒ Analiz sÄ±rasÄ±nda hata oluÅŸtu!")

if __name__ == "__main__":
    main()

#!/usr/bin/env python3
"""
Benzerlik AlgoritmasÄ± NasÄ±l Ã‡alÄ±ÅŸÄ±yor?
=====================================
"""

import re
from typing import List, Dict

class AlgorithmExplainer:
    def __init__(self):
        # Genel kelimeler (filtreleme iÃ§in)
        self.common_words = {
            'remix', 'mix', 'dj', 'feat', 'ft', 'music', 'song', 'mp3', 'm4a', 'flac', 'wmv',
            'the', 'a', 'an', 'and', 'or', 'of', 'in', 'on', 'at', 'to', 'for', 'with', 'by',
            'official', 'video', 'hd', 'version', 'edit', 'extended', 'radio', 'clean',
            'original', 'acoustic', 'live', 'studio', 'album', 'single', 'ep', 'lp',
            've', 'ile', 'iÃ§in', 'olan', 'gibi', 'kadar', 'sonra', 'Ã¶nce',
            'mÃ¼zik', 'ÅŸarkÄ±', 'parÃ§a'
        }
    
    def normalize_text(self, text: str) -> str:
        """1. ADIM: Metni normalize et"""
        print(f"ğŸ“ Orijinal metin: '{text}'")
        
        if not text:
            return ""
        
        # KÃ¼Ã§Ã¼k harfe Ã§evir
        text = text.lower()
        print(f"   â†’ KÃ¼Ã§Ã¼k harf: '{text}'")
        
        # TÃ¼rkÃ§e karakterleri dÃ¶nÃ¼ÅŸtÃ¼r
        char_map = {
            'Ã§': 'c', 'ÄŸ': 'g', 'Ä±': 'i', 'Ã¶': 'o', 'ÅŸ': 's', 'Ã¼': 'u',
            'Ã‡': 'c', 'Ä': 'g', 'Ä°': 'i', 'Ã–': 'o', 'Å': 's', 'Ãœ': 'u'
        }
        
        for tr_char, en_char in char_map.items():
            text = text.replace(tr_char, en_char)
        print(f"   â†’ TÃ¼rkÃ§e karakter dÃ¶nÃ¼ÅŸÃ¼mÃ¼: '{text}'")
        
        # Sadece harf ve rakam bÄ±rak
        text = re.sub(r'[^a-z0-9\s]', ' ', text)
        print(f"   â†’ Ã–zel karakter temizleme: '{text}'")
        
        # Ã‡oklu boÅŸluklarÄ± tek boÅŸluÄŸa Ã§evir
        text = re.sub(r'\s+', ' ', text)
        print(f"   â†’ BoÅŸluk normalizasyonu: '{text}'")
        
        return text.strip()
    
    def extract_words(self, text: str) -> List[str]:
        """2. ADIM: Metinden kelimeleri Ã§Ä±kar"""
        print(f"\nğŸ”¤ Kelime Ã§Ä±karma:")
        normalized = self.normalize_text(text)
        words = [word for word in normalized.split() if len(word) > 1]
        print(f"   â†’ Kelimeler: {words}")
        return words
    
    def filter_meaningful_words(self, words: List[str]) -> List[str]:
        """3. ADIM: AnlamlÄ± kelimeleri filtrele"""
        print(f"\nğŸ¯ AnlamlÄ± kelime filtresi:")
        print(f"   â†’ TÃ¼m kelimeler: {words}")
        print(f"   â†’ Genel kelimeler: {self.common_words}")
        
        meaningful = [w for w in words if w not in self.common_words]
        general = [w for w in words if w in self.common_words]
        
        print(f"   â†’ AnlamlÄ± kelimeler: {meaningful}")
        print(f"   â†’ Genel kelimeler: {general}")
        
        return meaningful
    
    def calculate_similarity_step_by_step(self, words1: List[str], words2: List[str]) -> float:
        """4. ADIM: Benzerlik hesaplama - AdÄ±m adÄ±m"""
        print(f"\nâš–ï¸  BENZERLÄ°K HESAPLAMA")
        print("=" * 50)
        
        if not words1 or not words2:
            print("âŒ BoÅŸ kelime listesi - 0.0 dÃ¶ndÃ¼r")
            return 0.0
        
        # 1. AnlamlÄ± kelime filtresi
        meaningful1 = self.filter_meaningful_words(words1)
        meaningful2 = self.filter_meaningful_words(words2)
        
        # EÄŸer anlamlÄ± kelime yoksa
        if not meaningful1 or not meaningful2:
            print("âš ï¸  AnlamlÄ± kelime yok - genel kelimeleri kullan")
            if not words1 or not words2:
                return 0.0
            exact_matches = sum(1 for word in words1 if word in words2)
            score = (exact_matches / max(len(words1), len(words2))) * 0.3
            print(f"   â†’ Genel kelime skoru: {score:.3f}")
            return score
        
        # 2. AnlamlÄ± kelime eÅŸleÅŸmesi (Ana skor)
        exact_meaningful_matches = sum(1 for word in meaningful1 if word in meaningful2)
        meaningful_score = exact_meaningful_matches / max(len(meaningful1), len(meaningful2))
        print(f"\nğŸ“Š Ana skor hesaplama:")
        print(f"   â†’ AnlamlÄ± eÅŸleÅŸmeler: {exact_meaningful_matches}")
        print(f"   â†’ Maksimum kelime sayÄ±sÄ±: {max(len(meaningful1), len(meaningful2))}")
        print(f"   â†’ Ana skor: {meaningful_score:.3f}")
        
        # 2.5. Minimum eÅŸleÅŸme kontrolÃ¼
        if exact_meaningful_matches < 2:
            print("âŒ Yetersiz eÅŸleÅŸme (< 2) - 0.0 dÃ¶ndÃ¼r")
            return 0.0
        
        # 3. Kelime uzunluk bonusu
        long_word_matches = sum(1 for word in meaningful1 if word in meaningful2 and len(word) >= 4)
        long_word_bonus = long_word_matches / max(len(meaningful1), len(meaningful2)) * 0.2
        print(f"\nğŸ“ Uzun kelime bonusu:")
        print(f"   â†’ Uzun kelime eÅŸleÅŸmeleri: {long_word_matches}")
        print(f"   â†’ Uzun kelime bonusu: {long_word_bonus:.3f}")
        
        # 4. SanatÃ§Ä± adÄ± bonusu
        artist_bonus = 0.0
        if meaningful1 and meaningful2:
            if meaningful1[0] == meaningful2[0] and len(meaningful1[0]) >= 3:
                artist_bonus = 0.1
                print(f"\nğŸ¤ SanatÃ§Ä± adÄ± bonusu:")
                print(f"   â†’ Ä°lk kelime eÅŸleÅŸmesi: '{meaningful1[0]}' == '{meaningful2[0]}'")
                print(f"   â†’ SanatÃ§Ä± bonusu: {artist_bonus:.3f}")
        
        # 5. ÅarkÄ± adÄ± bonusu
        song_bonus = 0.0
        if len(meaningful1) >= 2 and len(meaningful2) >= 2:
            if meaningful1[1] == meaningful2[1] and len(meaningful1[1]) >= 3:
                song_bonus = 0.2
                print(f"\nğŸµ ÅarkÄ± adÄ± bonusu:")
                print(f"   â†’ Ä°kinci kelime eÅŸleÅŸmesi: '{meaningful1[1]}' == '{meaningful2[1]}'")
                print(f"   â†’ ÅarkÄ± bonusu: {song_bonus:.3f}")
        
        # 6. Tam eÅŸleÅŸme bonusu
        full_match_bonus = 0.0
        if exact_meaningful_matches >= 3:
            full_match_bonus = 0.15
            print(f"\nğŸ† Tam eÅŸleÅŸme bonusu:")
            print(f"   â†’ EÅŸleÅŸme sayÄ±sÄ±: {exact_meaningful_matches} >= 3")
            print(f"   â†’ Tam eÅŸleÅŸme bonusu: {full_match_bonus:.3f}")
        
        # 7. Genel kelime penalty
        general_matches = sum(1 for word in words1 if word in words2 and word in self.common_words)
        general_word_penalty = min(0.2, general_matches * 0.05) if general_matches > 0 else 0.0
        print(f"\nâš ï¸  Genel kelime penalty:")
        print(f"   â†’ Genel kelime eÅŸleÅŸmeleri: {general_matches}")
        print(f"   â†’ Genel kelime penalty: {general_word_penalty:.3f}")
        
        # Toplam skor
        total_score = meaningful_score + long_word_bonus + artist_bonus + song_bonus + full_match_bonus - general_word_penalty
        print(f"\nğŸ¯ TOPLAM SKOR HESAPLAMA:")
        print(f"   â†’ Ana skor: {meaningful_score:.3f}")
        print(f"   â†’ Uzun kelime bonusu: +{long_word_bonus:.3f}")
        print(f"   â†’ SanatÃ§Ä± bonusu: +{artist_bonus:.3f}")
        print(f"   â†’ ÅarkÄ± bonusu: +{song_bonus:.3f}")
        print(f"   â†’ Tam eÅŸleÅŸme bonusu: +{full_match_bonus:.3f}")
        print(f"   â†’ Genel kelime penalty: -{general_word_penalty:.3f}")
        print(f"   â†’ TOPLAM SKOR: {total_score:.3f}")
        
        # 0.0 - 1.0 arasÄ±nda sÄ±nÄ±rla
        final_score = max(0.0, min(1.0, total_score))
        print(f"   â†’ FÄ°NAL SKOR: {final_score:.3f}")
        
        return final_score
    
    def explain_algorithm(self, file1: str, file2: str):
        """AlgoritmayÄ± adÄ±m adÄ±m aÃ§Ä±kla"""
        print(f"ğŸ” BENZERLÄ°K ALGORÄ°TMASI AÃ‡IKLAMASI")
        print("=" * 60)
        print(f"ğŸ“ Dosya 1: {file1}")
        print(f"ğŸ“ Dosya 2: {file2}")
        
        # Kelimeleri Ã§Ä±kar
        words1 = self.extract_words(file1)
        words2 = self.extract_words(file2)
        
        # Benzerlik hesapla
        similarity = self.calculate_similarity_step_by_step(words1, words2)
        
        print(f"\nğŸ¯ SONUÃ‡:")
        print(f"   â†’ Benzerlik skoru: {similarity:.3f}")
        print(f"   â†’ Threshold (0.85): {'âœ… GEÃ‡TÄ°' if similarity >= 0.85 else 'âŒ GEÃ‡MEDÄ°'}")
        
        return similarity

def main():
    """Ana fonksiyon"""
    explainer = AlgorithmExplainer()
    
    # Test durumlarÄ±
    test_cases = [
        {
            "file1": "Dr. Alban - Away From Home (2).mp4",
            "file2": "Dr. Alban - No Coke 2k24 (Dr. Luxe & DJ Finn & Lexy Key VIP Remix) www.clubberism.com.mp3",
            "description": "FarklÄ± ÅŸarkÄ±lar - aynÄ± sanatÃ§Ä±"
        },
        {
            "file1": "Ã‡elik - AteÅŸteyim (10).mp3", 
            "file2": "Ã‡elik - AteÅŸteyim.mp3",
            "description": "AynÄ± ÅŸarkÄ± - farklÄ± versiyonlar"
        }
    ]
    
    for i, test_case in enumerate(test_cases, 1):
        print(f"\n{'='*80}")
        print(f"TEST {i}: {test_case['description']}")
        print(f"{'='*80}")
        
        explainer.explain_algorithm(test_case['file1'], test_case['file2'])
        
        if i < len(test_cases):
            input("\nâ¸ï¸  Devam etmek iÃ§in Enter'a basÄ±n...")

if __name__ == "__main__":
    main()
